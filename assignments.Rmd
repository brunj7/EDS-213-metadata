---
title: "Assignments"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Week 1 

### Assignment 1.1 -- Journal club

#### Expectation:

- Everybody should read all the abstracts
- By group of 3, read carefully and prepare a 3-4 slides presentation about the paper / book chapter you have been assigned
- Participate in the discussion during the Journal club


#### Reading Resources

1. Borer, et al, 2009. Some Simple Guidelines for Effective Data Management. https://doi.org/10.1890/0012-9623-90.2.205

2. Fegraus, et al, 2005. Maximizing the Value of Ecological Data with Structured Metadata: An Introduction to Ecological Metadata Language (EML) and Principles for Metadata Creation.  https://doi.org/10.1890/0012-9623(2005)86[158:MTVOED]2.0.CO;2

3. Hampton, et al, 2015. The Tao of open science for ecology. Ecosphere 6, art120. https://doi.org/10.1890/ES14-00402.1

4. Heidorn, P.B., 2008. Shedding Light on the Dark Data in the Long Tail of Science. Library Trends 57, 280–299. https://doi.org/10.1353/lib.0.0036
5. Michener, W.K., 2015. Ten Simple Rules for Creating a Good Data Management Plan. PLOS Computational Biology 11, e1004525. https://doi.org/10.1371/journal.pcbi.1004525

6. Recknagel, F., Michener, W.K., 2018. Ecological Informatics: An Introduction, in: Recknagel, F., Michener, W.K. (Eds.), Ecological Informatics: Data Management and Knowledge Discovery. Springer International Publishing, Cham, pp. 3–10. https://doi.org/10.1007/978-3-319-59928-1_1

7. Michener, W.K., 2018. Ecological Informatics: Data Discovery, in: Recknagel, F., Michener, W.K. (Eds.), Ecological Informatics: Data Management and Knowledge Discovery. Springer International Publishing, Cham, pp. 3–10. https://doi.org/10.1007/978-3-319-59928-1_1

8. Schildhauer M.S., 2018. Ecological Informatics: Data Integration, in: Recknagel, F., Michener, W.K. (Eds.), Ecological Informatics: Data Management and Knowledge Discovery. Springer International Publishing, Cham, pp. 3–10. https://doi.org/10.1007/978-3-319-59928-1_1

9. Wilkinson, et al, 2016. The FAIR Guiding Principles for scientific data management and stewardship. Sci Data 3, 160018. https://doi.org/10.1038/sdata.2016.18

#### Group Project -- Teams

```{r journal club, cache=FALSE}
library(tidyverse)
library(DT)

# Set the random seed to make this reproducible
set.seed(12)

# Read the roster 
students <- read.csv("data/eds213_roster.csv")

# Randomly create the groups
groups <- students %>% 
  slice(sample(1:n())) %>% # randomly arrange the data frame
  group_by((row_number()-1) %/% (n()/9)) %>%  # create 9 Groups
  nest %>% pull() %>% bind_rows(.id = "Group") %>%  # group number as column
  datatable(options = list(pageLength = 25))   # Display

groups
```

#### Due date:

Wed 09/29/2021


### Assignment 1.2 -- Define your group project question

#### Expectation:

- Brainstorm as a group about your group project question
- Open an GitHub issue on [this repository](https://github.com/brunj7/EDS-213-group-project) describing:
  - Your environmental question
  - The type of data sets you are planning to search for on [ADC](https://arcticdata.io/catalog/data), [KNB](https://knb.ecoinformatics.org/) and/or [EDI](https://environmentaldatainitiative.org/) repositories via [DataONE](https://www.dataone.org/)
  - Link to your Group project repository on GitHub
  
**See [here](group_project.html) for more background information about the group project**

#### Project Teams

```{r group project, cache=FALSE}
library(tidyverse)
library(DT)

# Set the random seed to make this reproducible
set.seed(123)

# Read the roster 
students <- read.csv("data/eds213_roster.csv")

# Randomly create the groups
students %>% 
  slice(sample(1:n())) %>%   # randomly arrange the data frame
  group_by((row_number()-1) %/% (n()/7)) %>%  # create 7 Groups
  nest %>% pull() %>% bind_rows(.id = "Group") %>%  # group number as column
  datatable(options = list(pageLength = 25))   # Display


```



#### Due date:

**Wed 10/06/2021 at 12PM (Noon)**

<br>

---

<br>

## Week2

**Create a GitHub repository to store your codes of assignment 2.1 and 2.2.** Use your group project repository for 2.3.

### Assignment 2.1 --  `dataRetrieval`

1. Add the [Santa Paula Creek](https://waterdata.usgs.gov/nwis/uv?site_no=11113500) gauge to exercise we did in class
2. What is the best way to query multiple sites using this R package?
3. Create a plot showing any stream flow response to the rain of last night (10/04). Determine at what time did the stream flow peaked (if any) at the two locations?

### Assignment 2.2 --  `metajam`

Finish the exercise we started during the lab session to use `metajam` to download the Alaskan household languages data from DataONE. 

For inspiration Here is the code sample we started during the lab: https://brunj7.github.io/EDS-213-metadata/codes/metajam_session.html


**Push all your codes to a GitHub repository and add me (`brunj7`) as a collaborator to your repository.**



### Assignment 2.3 -- Use an API to retrieve data for your project

As your group project team:

1. Based and what we discussed this week, find an API that you could use to retrieve data you are using in your group project.

2. **In your Group project repository**, write a script to retrieve the data relying on this API. Don't forget to capture any information about how you found the data as well as any metadata in the Rmarkdown / jupyter notebook so an external user can understand the data set(s) and track their source / data provider. 


## Due date:

**Wed 10/13/2021 at 12PM (Noon)**
